================================================================================
DIAGNOSIS: WHY PAPERS #1-20 AREN'T CATCHING FPs
================================================================================

CURRENT STATE:
- 377 bugs remaining
- 292 FPs caught by Phase -2 (Quick Pre-Check)
- 0 FPs caught by any other phase/layer

ROOT CAUSE ANALYSIS:
================================================================================

1. PHASES THAT RUN:
   ✓ Phase -2 (Quick Pre-Check) - WORKS, catches 292 FPs
   ✓ Phase 0 (Semantic) - RUNS, but catches ~0 (only very specific patterns)
   ✓ Phase 1 (Dataflow/Interval) - RUNS, but catches ~0
   ✓ Phase 2 (Guard Barriers) - RUNS, but catches ~0
   ✗ Phase 3 (Layer 2: SOS/SDP) - SKIPPED (line 818: skip_expensive_layers = True)
   ✓ Phase 4 (Layer 4: ICE/Houdini) - RUNS (skip disabled line 854)
   ✓ Phase 6A (Layer 3: ICE Stdlib) - RUNS but FAILS (no bytecode instructions)
   ✓ Phase 6B (Layer 3: CEGAR) - RUNS but likely returns 'unsafe'
   ✓ Phase 7 (Layer 5: IC3) - RUNS but likely returns 'unsafe'

2. WHY LAYERS 1-5 (PAPERS #1-20) CATCH NOTHING:
   
   Issue A: Phase 3 (Layer 2) is SKIPPED entirely
   -----------------------------------------------
   Location: extreme_verification.py:818
   Code: skip_expensive_layers = True
   Result: SOS/SDP synthesis (Papers #1-4) never runs
   Impact: No synthesized barriers for later layers to refine
   
   Issue B: Later layers BUILD on Layer 2 output
   -----------------------------------------------
   - Layer 4 (ICE) uses: initial_barriers = layer2_barriers (line 889)
   - Layer 4 (Houdini) uses: layer2_barriers + layer4_learned (line 920)
   - Layer 3 (CEGAR) uses: guard_barriers + synthesized_barriers (line 979)
   
   Since Layer 2 is skipped, layer2_barriers = []
   → Later layers have no initial barriers to work with
   → They try verification from scratch, which is much harder
   → They return 'unsafe' / fail
   
   Issue C: Stdlib augmentation can't detect stdlib usage
   -----------------------------------------------
   Location: extreme_verification.py:970
   Check: hasattr(crash_summary, 'instructions')
   Result: Always False - summaries don't have bytecode instructions
   Impact: Papers #9-12 stdlib barrier synthesis never runs
   
   Issue D: Synthesized barriers depend on incomplete data
   -----------------------------------------------
   The synthesis engines need:
   - Intervals (from interval_analyzer) - basic, may work
   - Dataflow facts (from dataflow_analyzer) - basic, may work
   - ICE examples (from _collect_ice_examples) - needs good examples
   - Candidate annotations - may be too generic
   
   Without good initial data, synthesis fails → returns 'unsafe'

3. THE VERIFICATION FLOW PROBLEM:
   
   Current: Phase -2 → Phase 0 → Phase 1 → Phase 2 → [SKIP 3] → Phase 4-7 (fail)
   Expected: Phase -2 → Phase 0 → ... → Phase 3 → Phase 4 → ... (layered refinement)
   
   The papers are designed to build on each other:
   - Layer 1 (Foundations) provides tools for Layer 2
   - Layer 2 (SOS/SDP) synthesizes initial barriers
   - Layer 3 (CEGAR) refines Layer 2 barriers via abstraction
   - Layer 4 (ICE/Houdini) learns invariants using Layer 3 guidance
   - Layer 5 (IC3/CHC) inductively strengthens Layer 4 invariants
   
   By skipping Layer 2, we break the dependency chain!

================================================================================
SOLUTIONS
================================================================================

OPTION 1: Enable Layer 2 (Papers #1-4)
---------------------------------------
Change line 818 from:
  skip_expensive_layers = True
To:
  skip_expensive_layers = False

Pros: Allows proper layered verification
Cons: Slow (~2-3 minutes instead of 3 seconds)

OPTION 2: Fix stdlib detection without bytecode
-----------------------------------------------
Instead of checking instructions, use:
- return_guarantees (shows 'nonnull', 'non_negative', etc.)
- guard_type_to_vars (shows comparison guards, etc.)
- qualified_name (detect stdlib modules)

Implement barrier synthesis from these high-level abstractions.

OPTION 3: Hybrid approach
-------------------------
1. Enable Layer 2 but with timeout (e.g., 100ms per bug)
2. Fix stdlib detection to use available data
3. Add caching so Layer 2 results reuse across bugs

OPTION 4: Focus on what actually works
--------------------------------------
The current system catches 292/669 FPs (43.6%) with just Phase -2.
The remaining 377 bugs may actually be TRUE POSITIVES, not FPs.

Instead of trying to reduce FPs further:
- Validate that the 377 are real bugs
- Focus on reducing false negatives
- Improve bug prioritization/ranking

================================================================================
RECOMMENDATION
================================================================================

1. IMMEDIATE: Enable Layer 2 (change line 818)
2. SHORT-TERM: Measure if Layers 1-5 actually help with Layer 2 enabled
3. MEDIUM-TERM: If still no help, the issue is the verification engines themselves
4. LONG-TERM: Consider that 377 bugs may be the true positive set

The 25-paper system is architected correctly, but:
- Layer 2 is artificially disabled (line 818)
- Without Layer 2, layers 3-5 have nothing to refine
- This is why papers #1-20 catch 0 FPs
